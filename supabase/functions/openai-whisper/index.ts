
// This is already present in the files, but making sure it's here
import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    // Get the authorization header from the request
    const authHeader = req.headers.get('Authorization');
    if (!authHeader) {
      throw new Error('Missing Authorization header');
    }

    // Get the audio URL from the request body
    const { audioUrl } = await req.json();
    
    if (!audioUrl) {
      throw new Error('No audio URL provided');
    }

    // Check if this is a simulation request
    const isSimulation = audioUrl.includes('simulation-recording');
    
    if (isSimulation) {
      console.log('Simulation mode detected, returning mock response');
      
      // Return a mock response for simulations
      return new Response(
        JSON.stringify({
          transcription: "This is a simulated transcription. In a real scenario, this text would be generated by processing your audio file with OpenAI's Whisper API.",
          duration: 15.5,
          language: "en"
        }),
        { 
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
          status: 200
        }
      );
    }

    console.log('Processing audio transcription for URL:', audioUrl);

    // Fetch the audio file from the provided URL
    const audioResponse = await fetch(audioUrl);
    
    if (!audioResponse.ok) {
      throw new Error(`Failed to fetch audio file: ${audioResponse.statusText}`);
    }
    
    const audioBlob = await audioResponse.blob();
    console.log('Audio file fetched successfully, size:', audioBlob.size);
    
    // Create a FormData object to send to the OpenAI API
    const formData = new FormData();
    formData.append('file', audioBlob, 'audio.webm');
    formData.append('model', 'whisper-1');
    formData.append('language', 'en'); // Set language to English
    formData.append('response_format', 'verbose_json'); // Get detailed response
    
    // Call the OpenAI Whisper API
    const openaiApiKey = Deno.env.get('OPENAI_API_KEY');
    if (!openaiApiKey) {
      throw new Error('OpenAI API key not configured');
    }
    
    console.log('Calling OpenAI Whisper API...');
    const openaiResponse = await fetch('https://api.openai.com/v1/audio/transcriptions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiApiKey}`
      },
      body: formData
    });
    
    if (!openaiResponse.ok) {
      const errorText = await openaiResponse.text();
      throw new Error(`OpenAI API error: ${errorText}`);
    }
    
    const transcription = await openaiResponse.json();
    console.log('Transcription successful, length:', transcription.text.length);
    
    return new Response(
      JSON.stringify({
        transcription: transcription.text,
        duration: transcription.duration,
        language: transcription.language
      }),
      { 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        status: 200
      }
    );
  } catch (error) {
    console.error('Error in whisper function:', error);
    return new Response(
      JSON.stringify({ error: error.message }),
      { 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        status: 500
      }
    );
  }
});
